{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import Packages**"
      ],
      "metadata": {
        "id": "T4P9ngcJq6e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "0HBfjlBeA1rj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ],
      "metadata": {
        "id": "eony8A8OSjPb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangGraph æ¶æ§‹\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict"
      ],
      "metadata": {
        "id": "rNd43YezhcRL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Knowledge Base**"
      ],
      "metadata": {
        "id": "V-5T-88ctapz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ç›®å‰çŸ¥è­˜åº«\n",
        "# docs_text = \"\"\"\n",
        "# ç«å½±ä»£æ•¸\tå§“å\tå¸«å‚…\tå¾’å¼Ÿ\n",
        "# åˆä»£\tåƒæ‰‹æŸ±é–“\tç„¡æ˜ç¢ºè¨˜è¼‰\tçŒ¿é£›æ—¥æ–¬ã€æ°´æˆ¶é–€ç‚ã€è½‰å¯¢å°æ˜¥\n",
        "# äºŒä»£\tåƒæ‰‹æ‰‰é–“\tåƒæ‰‹æŸ±é–“ï¼ˆå…„é•·ï¼‰\tçŒ¿é£›æ—¥æ–¬ã€å¿—æ‘åœ˜è—ã€å®‡æ™ºæ³¢é¡ç­‰\n",
        "# ä¸‰ä»£\tçŒ¿é£›æ—¥æ–¬\tåƒæ‰‹æŸ±é–“ã€åƒæ‰‹æ‰‰é–“\tè‡ªä¾†ä¹Ÿã€å¤§è›‡ä¸¸ã€åƒæ‰‹ç¶±æ‰‹ï¼ˆå‚³èªªä¸‰å¿ï¼‰\n",
        "# å››ä»£\tæ³¢é¢¨æ¹Š\tè‡ªä¾†ä¹Ÿ\tæ——æœ¨å¡å¡è¥¿ã€å®‡æ™ºæ³¢å¸¶åœŸã€é‡åŸç³\n",
        "# äº”ä»£\tåƒæ‰‹ç¶±æ‰‹\tçŒ¿é£›æ—¥æ–¬\tæ˜¥é‡æ«»ã€å¿—ä¹ƒç­‰ï¼ˆä¸»è¦ç‚ºæ˜¥é‡æ«»ï¼‰\n",
        "# å…­ä»£\tæ——æœ¨å¡å¡è¥¿\tæ³¢é¢¨æ¹Š\tæ¼©æ¸¦é³´äººã€å®‡æ™ºæ³¢ä½åŠ©ã€æ˜¥é‡æ«»ï¼ˆç¬¬ä¸ƒç­ï¼‰\n",
        "# ä¸ƒä»£\tæ¼©æ¸¦é³´äºº\tè‡ªä¾†ä¹Ÿã€æ——æœ¨å¡å¡è¥¿\tæœ¨è‘‰ä¸¸ç­‰ï¼ˆä¸»è¦ç‚ºæœ¨è‘‰ä¸¸ï¼‰\n",
        "# \"\"\""
      ],
      "metadata": {
        "id": "j_pvpH--d-qW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_text = '''\n",
        "    \"åˆä»£ç«å½±æ˜¯åƒæ‰‹æŸ±é–“ï¼Œæ²’æœ‰æ˜ç¢ºçš„å¸«å‚…ï¼Œä»–çš„å¾’å¼Ÿæ˜¯çŒ¿é£›æ—¥æ–¬ã€æ°´æˆ¶é–€ç‚èˆ‡è½‰å¯¢å°æ˜¥ã€‚\",\n",
        "    \"äºŒä»£ç«å½±æ˜¯åƒæ‰‹æ‰‰é–“ï¼Œæ˜¯åƒæ‰‹æŸ±é–“çš„å¼Ÿå¼Ÿï¼Œä»–çš„å¾’å¼Ÿæœ‰çŒ¿é£›æ—¥æ–¬ã€å¿—æ‘åœ˜è—èˆ‡å®‡æ™ºæ³¢é¡ã€‚\",\n",
        "    \"ä¸‰ä»£ç«å½±æ˜¯çŒ¿é£›æ—¥æ–¬ï¼Œå¸«æ‰¿åƒæ‰‹æŸ±é–“èˆ‡åƒæ‰‹æ‰‰é–“ï¼Œå¾’å¼Ÿæ˜¯è‡ªä¾†ä¹Ÿã€å¤§è›‡ä¸¸èˆ‡åƒæ‰‹ç¶±æ‰‹ï¼ˆå‚³èªªä¸‰å¿ï¼‰ã€‚\",\n",
        "    \"å››ä»£ç«å½±æ˜¯æ³¢é¢¨æ¹Šï¼Œå¸«å‚…æ˜¯è‡ªä¾†ä¹Ÿï¼Œä»–çš„å¾’å¼Ÿæœ‰æ——æœ¨å¡å¡è¥¿ã€å®‡æ™ºæ³¢å¸¶åœŸèˆ‡é‡åŸç³ã€‚\",\n",
        "    \"äº”ä»£ç«å½±æ˜¯åƒæ‰‹ç¶±æ‰‹ï¼Œå¸«å‚…æ˜¯çŒ¿é£›æ—¥æ–¬ï¼Œå¥¹çš„å¾’å¼Ÿä¸»è¦æ˜¯æ˜¥é‡æ«»ï¼Œé‚„æœ‰å¿—ä¹ƒã€‚\",\n",
        "    \"å…­ä»£ç«å½±æ˜¯æ——æœ¨å¡å¡è¥¿ï¼Œå¸«å‚…æ˜¯æ³¢é¢¨æ¹Šï¼Œä»–çš„å¾’å¼Ÿæ˜¯æ¼©æ¸¦é³´äººã€å®‡æ™ºæ³¢ä½åŠ©èˆ‡æ˜¥é‡æ«»ï¼ˆç¬¬ä¸ƒç­ï¼‰ã€‚\",\n",
        "    \"ä¸ƒä»£ç«å½±æ˜¯æ¼©æ¸¦é³´äººï¼Œä»–çš„å¸«å‚…æ˜¯è‡ªä¾†ä¹Ÿèˆ‡æ——æœ¨å¡å¡è¥¿ï¼Œä»–çš„å¾’å¼Ÿæ˜¯æœ¨è‘‰ä¸¸ã€‚\"\n",
        "'''"
      ],
      "metadata": {
        "id": "-XR-M2BG-Zxv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Models**"
      ],
      "metadata": {
        "id": "2HhaOsy6za7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = SentenceTransformer('shibing624/text2vec-base-chinese')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfYuVxPjSvsV",
        "outputId": "93fc8a4b-3ccd-4477-80fe-e27b1d5f705c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B-Chat\", trust_remote_code=True)\n",
        "chat_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen1.5-0.5B-Chat\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "lzr1nd6ZWNT1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_embeddings = embed_model.encode(docs_text)"
      ],
      "metadata": {
        "id": "Fi3YJ_B9Fd2m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Excute Chatbot**"
      ],
      "metadata": {
        "id": "0TZpiOc2z6m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… ç‹€æ…‹å®šç¾©\n",
        "class AppState(TypedDict):\n",
        "    user_query: str\n",
        "    rag_trigger: bool\n",
        "    docs: str\n",
        "    answer: str\n",
        "    mode: str  # æ–°å¢æ¨¡å¼å­—æ®µ\n",
        "\n",
        "# âœ… ç¯€é»1ï¼šEmbedding + ç›¸ä¼¼åº¦åˆ†æµ\n",
        "def embed_node(state: AppState) -> AppState:\n",
        "    query = state[\"user_query\"]\n",
        "\n",
        "    query_vec = np.atleast_2d(embed_model.encode(query))  # Query encoding\n",
        "    doc_embeddings_2d = np.atleast_2d(np.asarray(doc_embeddings))  # Doc embeddings\n",
        "\n",
        "    similarities = cosine_similarity(query_vec, doc_embeddings_2d)[0]\n",
        "\n",
        "    # è¨­å®šç›¸ä¼¼åº¦é–¾å€¼ç‚ºnè‹¥ä»»ä½•æ–‡æª”çš„ç›¸ä¼¼åº¦å¤§æ–¼é–¾å€¼ï¼Œå•Ÿå‹• RAG æ¨¡å¼\n",
        "    rag_trigger = any(similarity > 0.6 for similarity in similarities)\n",
        "\n",
        "    # è¿”å›ç›¸ä¼¼åº¦å¤§æ–¼nçš„æ–‡æª”\n",
        "    matched = \"\\n\".join([docs_text[i] for i, similarity in enumerate(similarities) if similarity > 0.6])\n",
        "\n",
        "    return {**state, \"rag_trigger\": rag_trigger, \"docs\": matched, \"mode\": \"knowledge_base\" if rag_trigger else \"chat\"}\n",
        "\n",
        "# âœ… ç¯€é»2ï¼šæ±ºç­– routerï¼ˆæ ¹æ“šæŸ¥è©¢æ±ºå®šæ˜¯å¦ä½¿ç”¨çŸ¥è­˜åº«æª¢ç´¢æˆ–æ™®é€šèŠå¤©ï¼‰\n",
        "def decision_node(state: AppState) -> AppState:\n",
        "    # æ ¹æ“š rag_trigger æ±ºå®šä¸‹ä¸€æ­¥è™•ç†ç¯€é»\n",
        "    if state[\"rag_trigger\"]:\n",
        "        return {**state, \"mode\": \"knowledge_base\"}\n",
        "    else:\n",
        "        return {**state, \"mode\": \"chat\"}\n",
        "\n",
        "# âœ… ç¯€é»3ï¼šRAG å›ç­”æ¨¡å¼\n",
        "def rag_node(state: AppState) -> AppState:\n",
        "    query = state[\"user_query\"]\n",
        "    matched_knowledge = state[\"docs\"]\n",
        "    print(\"ğŸ” åŒ¹é…çŸ¥è­˜ï¼š\\n\", matched_knowledge)\n",
        "\n",
        "    # ğŸ§  æ”¹è‰¯å¾Œçš„æç¤ºèª\n",
        "    rag_prompt = f\"\"\"ä½ æ˜¯ä¸€ä½ç«å½±å¿è€…çš„çŸ¥è­˜å°ˆå®¶ã€‚ä»¥ä¸‹æ˜¯ä¾†è‡ªçŸ¥è­˜åº«çš„è³‡æ–™ï¼Œå…§å®¹åŒ…å«ç«å½±è§’è‰²çš„å¸«å¾’é—œä¿‚ã€‚\n",
        "è«‹ä½ **åªæ ¹æ“šè³‡æ–™å›ç­”å•é¡Œ**ï¼Œ**ä¸è¦è£œå……å•é¡Œä¸­æœªå•åŠçš„å…¶ä»–è³‡è¨Š**ã€‚ç¦æ­¢ç·¨é€ æˆ–çŒœæ¸¬ã€‚\n",
        "è«‹æ˜ç¢ºæ–·èª°æ˜¯ç«å½±ï¼Œä»¥åŠè©²ç«å½±çš„å¸«å‚…æ˜¯èª°ï¼Œä»¥åŠè©²å¤¥å½±çš„å¾’å¼Ÿæœ‰å“ªäº›äºº\n",
        "\n",
        "å¦‚æœæ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œè«‹å›ç­”ã€Œæˆ‘ä¸çŸ¥é“ã€ã€‚\n",
        "\n",
        "ã€è³‡æ–™ã€‘\n",
        "{matched_knowledge}\n",
        "\n",
        "ã€å•é¡Œã€‘\n",
        "{query}\n",
        "\n",
        "è«‹ç°¡æ½”å›ç­”ï¼Œ**åªé‡å°å•é¡Œå…§å®¹åšå‡ºå›æ‡‰ï¼Œä¸å¤šèªªã€‚**\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½ç«å½±çŸ¥è­˜åŠ©æ‰‹ï¼Œåƒ…èƒ½æ ¹æ“šæä¾›çš„è³‡æ–™å›ç­”å•é¡Œï¼Œç¦æ­¢æé€ ã€‚\"},\n",
        "        {\"role\": \"user\", \"content\": rag_prompt}\n",
        "    ]\n",
        "\n",
        "    prompt_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    model_inputs = tokenizer([prompt_text], return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = chat_model.generate(**model_inputs, max_new_tokens=256)\n",
        "\n",
        "    output = tokenizer.batch_decode(generated_ids[:, model_inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
        "\n",
        "    return {**state, \"answer\": output.strip(), \"mode\": \"knowledge_base\", \"next_node\": \"END\"}\n",
        "\n",
        "\n",
        "# âœ… ç¯€é»4ï¼šä¸€èˆ¬èŠå¤©æ¨¡å¼\n",
        "def chat_answer_node(state: AppState) -> AppState:\n",
        "    query = state[\"user_query\"]\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½è¦ªåˆ‡çš„åŠ©ç†\"},\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ]\n",
        "    prompt_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer([prompt_text], return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = chat_model.generate(**inputs, max_new_tokens=256)\n",
        "    output = tokenizer.batch_decode(generated_ids[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
        "    return {**state, \"answer\": output, \"mode\": \"chat\", \"next_node\": \"END\"}\n",
        "\n",
        "# âœ… ç¯€é»5ï¼šè·¯ç”±ç¯€é»ï¼ˆæ ¹æ“š decision_node çš„çµæœæ±ºå®šèª¿ç”¨å“ªå€‹ç¯€é»ï¼‰\n",
        "def route_node(state: AppState) -> AppState:\n",
        "    if state[\"mode\"] == \"knowledge_base\":\n",
        "        return rag_node(state)  # å¦‚æœæ˜¯çŸ¥è­˜åº«æª¢ç´¢æ¨¡å¼\n",
        "    else:\n",
        "        return chat_answer_node(state)  # æ™®é€šèŠå¤©æ¨¡å¼\n",
        "\n",
        "# âœ… å»ºç«‹ LangGraph\n",
        "workflow = StateGraph(AppState)\n",
        "workflow.add_node(\"embed\", embed_node)\n",
        "workflow.add_node(\"decision\", decision_node)\n",
        "workflow.add_node(\"route\", route_node)  # æ–°å¢è·¯ç”±ç¯€é»\n",
        "workflow.add_node(\"__rag__\", rag_node)\n",
        "workflow.add_node(\"__chat__\", chat_answer_node)\n",
        "workflow.set_entry_point(\"embed\")\n",
        "workflow.add_edge(\"embed\", \"decision\")\n",
        "workflow.add_edge(\"decision\", \"route\")  # ç”± decision é€²è¡Œè·¯ç”±\n",
        "workflow.add_edge(\"route\", END)  # è·¯ç”±çµæŸ\n",
        "app = workflow.compile()\n",
        "\n",
        "# âœ… äº’å‹•æ¸¬è©¦è¿´åœˆ\n",
        "print(\"ğŸ” å•Ÿå‹•äº’å‹•æ¨¡å¼ï¼Œè¼¸å…¥ 'çµæŸ' çµæŸå°è©±\")\n",
        "while True:\n",
        "    query = input(\"ğŸ§‘ æ‚¨ï¼š\")\n",
        "    if query.strip() in [\"exit\", \"çµæŸ\", \"quit\"]:\n",
        "        print(\"ğŸ‘‹ å†è¦‹ï¼\")\n",
        "        break\n",
        "    result = app.invoke({\"user_query\": query})\n",
        "    print(f\"ğŸ¤– æ©Ÿå™¨äººï¼ˆæ¨¡å¼: {result['mode']}ï¼‰ï¼š{result['answer']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrMM84xU1wqL",
        "outputId": "7f768e18-7056-42dc-df6b-23dbd7c7242a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” å•Ÿå‹•äº’å‹•æ¨¡å¼ï¼Œè¼¸å…¥ 'çµæŸ' çµæŸå°è©±\n",
            "ğŸ§‘ æ‚¨ï¼šç¬¬å››ä»£ç«å½±æ˜¯èª°\n",
            "ğŸ” åŒ¹é…çŸ¥è­˜ï¼š\n",
            " å››ä»£ç«å½±æ˜¯æ³¢é¢¨æ¹Šï¼Œå¸«å‚…æ˜¯è‡ªä¾†ä¹Ÿï¼Œä»–çš„å¾’å¼Ÿæœ‰æ——æœ¨å¡å¡è¥¿ã€å®‡æ™ºæ³¢å¸¶åœŸèˆ‡é‡åŸç³ã€‚\n",
            "ğŸ¤– æ©Ÿå™¨äººï¼ˆæ¨¡å¼: knowledge_baseï¼‰ï¼šæˆ‘çŸ¥é“ï¼Œç¬¬å››ä»£ç«å½±æ˜¯æ³¢é¢¨æ¹Šã€‚\n",
            "ğŸ§‘ æ‚¨ï¼šç¬¬å››ä»£ç«å½±çš„å¾’å¼Ÿæœ‰å“ªäº›äºº\n",
            "ğŸ” åŒ¹é…çŸ¥è­˜ï¼š\n",
            " åˆä»£ç«å½±æ˜¯åƒæ‰‹æŸ±é–“ï¼Œæ²’æœ‰æ˜ç¢ºçš„å¸«å‚…ï¼Œä»–çš„å¾’å¼Ÿæ˜¯çŒ¿é£›æ—¥æ–¬ã€æ°´æˆ¶é–€ç‚èˆ‡è½‰å¯¢å°æ˜¥ã€‚\n",
            "å››ä»£ç«å½±æ˜¯æ³¢é¢¨æ¹Šï¼Œå¸«å‚…æ˜¯è‡ªä¾†ä¹Ÿï¼Œä»–çš„å¾’å¼Ÿæœ‰æ——æœ¨å¡å¡è¥¿ã€å®‡æ™ºæ³¢å¸¶åœŸèˆ‡é‡åŸç³ã€‚\n",
            "äº”ä»£ç«å½±æ˜¯åƒæ‰‹ç¶±æ‰‹ï¼Œå¸«å‚…æ˜¯çŒ¿é£›æ—¥æ–¬ï¼Œå¥¹çš„å¾’å¼Ÿä¸»è¦æ˜¯æ˜¥é‡æ«»ï¼Œé‚„æœ‰å¿—ä¹ƒã€‚\n",
            "å…­ä»£ç«å½±æ˜¯æ——æœ¨å¡å¡è¥¿ï¼Œå¸«å‚…æ˜¯æ³¢é¢¨æ¹Šï¼Œä»–çš„å¾’å¼Ÿæ˜¯æ¼©æ¸¦é³´äººã€å®‡æ™ºæ³¢ä½åŠ©èˆ‡æ˜¥é‡æ«»ï¼ˆç¬¬ä¸ƒç­ï¼‰ã€‚\n",
            "ä¸ƒä»£ç«å½±æ˜¯æ¼©æ¸¦é³´äººï¼Œä»–çš„å¸«å‚…æ˜¯è‡ªä¾†ä¹Ÿèˆ‡æ——æœ¨å¡å¡è¥¿ï¼Œä»–çš„å¾’å¼Ÿæ˜¯æœ¨è‘‰ä¸¸ã€‚\n",
            "ğŸ¤– æ©Ÿå™¨äººï¼ˆæ¨¡å¼: knowledge_baseï¼‰ï¼šæ——æœ¨å¡å¡è¥¿ã€å®‡æ™ºæ³¢å¸¶åœŸèˆ‡é‡åŸç³ç‚ºç¬¬å››ä»£ç«å½±çš„å¾’å¼Ÿã€‚\n",
            "ğŸ§‘ æ‚¨ï¼šç¬¬ä¸ƒä»£ç«å½±æ˜¯èª°\n",
            "ğŸ” åŒ¹é…çŸ¥è­˜ï¼š\n",
            " å…­ä»£ç«å½±æ˜¯æ——æœ¨å¡å¡è¥¿ï¼Œå¸«å‚…æ˜¯æ³¢é¢¨æ¹Šï¼Œä»–çš„å¾’å¼Ÿæ˜¯æ¼©æ¸¦é³´äººã€å®‡æ™ºæ³¢ä½åŠ©èˆ‡æ˜¥é‡æ«»ï¼ˆç¬¬ä¸ƒç­ï¼‰ã€‚\n",
            "ä¸ƒä»£ç«å½±æ˜¯æ¼©æ¸¦é³´äººï¼Œä»–çš„å¸«å‚…æ˜¯è‡ªä¾†ä¹Ÿèˆ‡æ——æœ¨å¡å¡è¥¿ï¼Œä»–çš„å¾’å¼Ÿæ˜¯æœ¨è‘‰ä¸¸ã€‚\n",
            "ğŸ¤– æ©Ÿå™¨äººï¼ˆæ¨¡å¼: knowledge_baseï¼‰ï¼šæ¼©æ¸¦é³´äºº\n",
            "ğŸ§‘ æ‚¨ï¼šä½ å¥½ï¼Œä½ æ˜¯ä»€éº¼æ¨¡å‹\n",
            "ğŸ¤– æ©Ÿå™¨äººï¼ˆæ¨¡å¼: chatï¼‰ï¼šæˆ‘æ˜¯ä¸€å€‹èŠå¤©æ©Ÿå°ï¼Œæˆ‘å«é€šç¾©åƒå•ã€‚æˆ‘å¯ä»¥å›ç­”å•é¡Œã€æä¾›ä¿¡æ¯ã€èŠå¤©ç­‰å„ç¨®ä»»å‹™ï¼Œè«‹éš¨æ™‚é—®æˆ‘ä»»ä½•å•é¡Œï¼\n",
            "ğŸ§‘ æ‚¨ï¼šçµæŸ\n",
            "ğŸ‘‹ å†è¦‹ï¼\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}